{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the trained filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some startup! \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# This is needed to save images \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure that caffe is on the python path\n",
    "caffe_root = '/path/to/caffe/'\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "\n",
    "# should work if you have made pycaffe\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu() # change to gpu if your machine has one \n",
    "# when you visualize the 2 layer NN / convnet, make sure to put appropriate paths \n",
    "# for the below fields\n",
    "PRETRAINED = '/path/to/hw1/2_caffe/logreg/logreg-snapshot/_iter_10000.caffemodel'\n",
    "MODEL = '/path/to/hw1/2_caffe/logreg/deploy.prototxt'\n",
    "\n",
    "# initialize net\n",
    "net = caffe.Classifier(MODEL,PRETRAINED)\n",
    "# you should see caffe initialize! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the parameters and their shapes (bias is omitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(k, v[0].data.shape) for k, v in net.params.items()]\n",
    "# this will print out all the names and shapes of the trained parameters. In logistic regression \n",
    "# it is just one layer 'fc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# collect all the weights\n",
    "w = net.params['fc1'][0].data # extract the layer from which you need to visualize\n",
    "# reshape the parameters to image size\n",
    "w = w.reshape((10,32,32,3))\n",
    "\n",
    "# obtain min,max to normalize\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "# classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# init figure \n",
    "fig = plt.figure(figsize=(6,6))\n",
    "for i in range(10):\n",
    "    wimg = 255.0*(w[i].squeeze() - w_min) / (w_max - w_min)\n",
    "    # subplot is (2,5) as ten filters are to be visualized\n",
    "    fig.add_subplot(2,5,i+1).imshow(wimg.astype('uint8'))\n",
    "# save fig! \n",
    "fig.savefig('logreg/logreg_filt.png')\n",
    "print 'figure saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vis_utils.py has helper code to view multiple filters in single image. Use this to visuzlize \n",
    "# neural network adn convnets. \n",
    "# import vis_utils\n",
    "from vis_utils import visualize_grid\n",
    "# saving the weights is now as simple as:\n",
    "plt.imsave('logreg/logreg_gridfilt.png',visualize_grid(w, padding=3).astype('uint8'))\n",
    "# padding is the space between images. Make sure that w is of shape: (N,H,W,C)\n",
    "print 'figure saved as a grid!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
